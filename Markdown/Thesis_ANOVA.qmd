---
title: "Thesis Lake Comparisons/Anovas"
author: "Jackson Barnett"
format: html
editor: visual
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo = FALSE,      # Hide the code
  warning = FALSE,   # Suppress warnings
  message = FALSE    # Suppress messages
)

```

```{r}

library(tidyverse)

anovaurl <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQITosV0R3R05ian-EG4t63j7WrelOlvvPOjiu9PWiiuKqfX-7yNO71oDoHFLGROfyG95oOHh0lIMGi/pub?gid=0&single=true&output=csv"

thes <- read_csv(anovaurl)

```

## KD Comparison By Lakes

```{r}

library(ggplot2)

# Create the box-and-whisker plot grouped by Lake
ggplot(thes, aes(x = Lake, y = kd)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, fill = "lightblue") +
  labs(
    title = "Light Attenuation (kd) by Lake",
    x = "Lake",
    y = "kd"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for readability
  )


```

```{r}

library(multcompView)  # For Tukey HSD visualizations

# Perform Tukey HSD test
tukey_results <- TukeyHSD(aov(kd ~ Lake, data = thes))$Lake

# Convert to a data frame
tukey_df <- as.data.frame(tukey_results)
tukey_df$Comparison <- rownames(tukey_df)

# Add a column for significance
tukey_df$Significant <- tukey_df$`p adj` < 0.05

# Plot Tukey HSD results
ggplot(tukey_df, aes(x = Comparison, y = diff, ymin = lwr, ymax = upr, color = Significant)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Tukey HSD Results: kd by Lake",
    x = "Comparison",
    y = "Difference in Means"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "gray"),
                     labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")) +
  theme(legend.position = "bottom")

```

## Predictor Comparison By Lake

```{r}

library(dplyr)
library(tidyr)

# Gather the variables into a long format for easier plotting
long_data <- thes %>%
  pivot_longer(cols = c(CDOM_ab, TSS, CHLa_Corrected, CHLa_Uncorrected), 
               names_to = "Variable", 
               values_to = "Value") %>%
  mutate(
    Variable = factor(
      Variable,
      levels = c("CDOM_ab", "TSS", "CHLa_Corrected", "CHLa_Uncorrected") # Set the desired order
    )
  )

# Create the combined box-and-whisker plot
ggplot(long_data, aes(x = Lake, y = Value)) +
  geom_boxplot(outlier.color = "red", outlier.shape = 16, fill = "lightblue") +
  facet_wrap(~ Variable, scales = "free_y") +  # Separate plots for each variable
  labs(
    title = "CDOM, TSS, Corrected and Uncorrected CHLa by Lake",
    x = "Lake",
    y = "Value"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 6),  # Rotate and shrink x-axis labels
    strip.text = element_text(size = 10)  # Adjust facet label size
  )

```

```{r}

# Perform Tukey HSD test
tukey_results <- TukeyHSD(aov(CDOM_ab ~ Lake, data = thes))$Lake

# Convert to a data frame
tukey_df <- as.data.frame(tukey_results)
tukey_df$Comparison <- rownames(tukey_df)

# Add a column for significance
tukey_df$Significant <- tukey_df$`p adj` < 0.05

# Plot Tukey HSD results
ggplot(tukey_df, aes(x = Comparison, y = diff, ymin = lwr, ymax = upr, color = Significant)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Tukey HSD Results: CDOM absorbance by Lake",
    x = "Comparison",
    y = "Difference in Means"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "gray"),
                     labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")) +
  theme(legend.position = "bottom")


```

```{r}

# Perform Tukey HSD test
tukey_results <- TukeyHSD(aov(TSS ~ Lake, data = thes))$Lake

# Convert to a data frame
tukey_df <- as.data.frame(tukey_results)
tukey_df$Comparison <- rownames(tukey_df)

# Add a column for significance
tukey_df$Significant <- tukey_df$`p adj` < 0.05

# Plot Tukey HSD results
ggplot(tukey_df, aes(x = Comparison, y = diff, ymin = lwr, ymax = upr, color = Significant)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Tukey HSD Results: TSS by Lake",
    x = "Comparison",
    y = "Difference in Means"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "gray"),
                     labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")) +
  theme(legend.position = "bottom")

```

```{r}

# Perform Tukey HSD test
tukey_results <- TukeyHSD(aov(CHLa_Corrected ~ Lake, data = thes))$Lake

# Convert to a data frame
tukey_df <- as.data.frame(tukey_results)
tukey_df$Comparison <- rownames(tukey_df)

# Add a column for significance
tukey_df$Significant <- tukey_df$`p adj` < 0.05

# Plot Tukey HSD results
ggplot(tukey_df, aes(x = Comparison, y = diff, ymin = lwr, ymax = upr, color = Significant)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Tukey HSD Results: Corrected CHLa by Lake",
    x = "Comparison",
    y = "Difference in Means"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "gray"),
                     labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")) +
  theme(legend.position = "bottom")

```

```{r}

# Perform Tukey HSD test
tukey_results <- TukeyHSD(aov(CHLa_Uncorrected ~ Lake, data = thes))$Lake

# Convert to a data frame
tukey_df <- as.data.frame(tukey_results)
tukey_df$Comparison <- rownames(tukey_df)

# Add a column for significance
tukey_df$Significant <- tukey_df$`p adj` < 0.05

# Plot Tukey HSD results
ggplot(tukey_df, aes(x = Comparison, y = diff, ymin = lwr, ymax = upr, color = Significant)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Tukey HSD Results: Uncorrected CHLa by Lake",
    x = "Comparison",
    y = "Difference in Means"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("TRUE" = "blue", "FALSE" = "gray"),
                     labels = c("TRUE" = "Significant", "FALSE" = "Not Significant")) +
  theme(legend.position = "bottom")


```

## Station Average Original Regression Analysis

```{r}

library(dplyr)

# Calculate means for each Site
mean_values <- thes %>%
  group_by(Site) %>%
  summarise(
    mean_kd = mean(kd, na.rm = TRUE),
    mean_CDOM_ab = mean(CDOM_ab, na.rm = TRUE),
    mean_CHLa_Corrected = mean(CHLa_Corrected, na.rm = TRUE),
    mean_TSS = mean(TSS, na.rm = TRUE)
  )

# View the result
print(mean_values)


```

```{r}
library(dplyr)
library(ggplot2)

# Calculate mean values for each Site
mean_values <- thes %>%
  group_by(Site) %>%
  summarise(
    mean_kd = mean(kd, na.rm = TRUE),
    mean_CDOM_ab = mean(CDOM_ab, na.rm = TRUE)
  )

# Perform linear regression
reg_model <- lm(mean_kd ~ mean_CDOM_ab, data = mean_values)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 4)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(mean_values, aes(x = mean_CDOM_ab, y = mean_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Station Average kd and CDOM",
    x = "CDOM Absorbance",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_CDOM_ab), 
      y = min(mean_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )


```

```{r}

mean_values <- thes %>%
  group_by(Site) %>%
  summarise(
    mean_kd = mean(kd, na.rm = TRUE),
    mean_TSS = mean(TSS, na.rm = TRUE)
  )

# Perform linear regression
reg_model <- lm(mean_kd ~ mean_TSS, data = mean_values)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 4)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(mean_values, aes(x = mean_TSS, y = mean_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Station Average kd and TSS",
    x = "TSS (mg/L)",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_TSS), 
      y = min(mean_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )
```

```{r}

mean_values <- thes %>%
  group_by(Site) %>%
  summarise(
    mean_kd = mean(kd, na.rm = TRUE),
    mean_CHLa_Corrected = mean(CHLa_Corrected, na.rm = TRUE)
  )

# Perform linear regression
reg_model <- lm(mean_kd ~ mean_CHLa_Corrected, data = mean_values)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 4)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(mean_values, aes(x = mean_CHLa_Corrected, y = mean_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Station Average kd and Corrected CHLa",
    x = "CHLa (ug/L)",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_CHLa_Corrected), 
      y = min(mean_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )
```

## Station Average Regressions Subtracting Residuals


```{r}
library(dplyr)
library(ggplot2)

# Calculate mean values for each Site
mean_values <- thes %>%
  group_by(Site) %>%
  summarise(
    mean_kd = mean(kd, na.rm = TRUE),
    mean_CDOM_ab = mean(CDOM_ab, na.rm = TRUE),
    mean_CHLa_Corrected = mean(CHLa_Corrected, na.rm = TRUE),
    mean_TSS = mean(TSS, na.rm = TRUE)
  )

# Perform linear regression
reg_model <- lm(mean_kd ~ mean_CDOM_ab, data = mean_values)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 4)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(mean_values, aes(x = mean_CDOM_ab, y = mean_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Station Average kd and CDOM",
    x = "CDOM Absorbance",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_CDOM_ab), 
      y = min(mean_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )


```

```{r}

residual_df <- mean_values |>
  group_by(Site) |>
  mutate(
    kd_CDOM = 0.1895*mean_CDOM_ab,
    residual_kd = mean_kd - kd_CDOM)|>
  select(Site, mean_kd, mean_CDOM_ab, mean_CHLa_Corrected, mean_TSS, kd_CDOM, residual_kd
  )

```


```{r}

reg_model <- lm(residual_kd ~ mean_TSS, data = residual_df)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 6)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(residual_df, aes(x = mean_TSS, y = residual_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Residual kd after CDOM vs TSS",
    x = "TSS (mg/L)",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_TSS), 
      y = min(residual_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )
```

```{r}

reg_model <- lm(residual_kd ~ mean_CHLa_Corrected, data = residual_df)

# Extract regression statistics
summary_model <- summary(reg_model)
slope <- round(coef(reg_model)[2], 4)
intercept <- round(coef(reg_model)[1], 4)
r_squared <- round(summary_model$r.squared, 4)
p_value <- round(summary_model$coefficients[2, 4], 6)

# Create regression equation text
reg_text <- paste0("y = ", slope, "x", " + ", intercept, "\n",
                   "R² = ", r_squared, ", p = ", p_value)

# Plot the regression
ggplot(residual_df, aes(x = mean_CHLa_Corrected, y = residual_kd)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Regression of Residual kd after CDOM vs CHLa",
    x = "CHLa (ug/L)",
    y = "kd (m-1)"
  ) +
  geom_text(
    aes(
      x = max(mean_CHLa_Corrected), 
      y = min(residual_kd), 
      label = reg_text
    ),
    hjust = 1, vjust = -1, size = 3 
  ) +
  theme_minimal() +
  theme(
    axis.line = element_line(color = "black", size = 1)  # Adds black axis lines
  )
```

```{r}

final_residual_df <- residual_df |>
  group_by(Site) |>
  mutate(
    kd_CDOM = 0.1895*mean_CDOM_ab,
    prop_kd_CDOM = (kd_CDOM/mean_kd)*100,
    kd_TSS = 0.1709*mean_TSS,
    prop_kd_TSS = (kd_TSS/mean_kd)*100,
    kd_CHLa = 0.0384*mean_CHLa_Corrected,
    prop_kd_CHLa = (kd_CHLa/mean_kd)*100)|>
  select(Site, mean_kd, prop_kd_CDOM, prop_kd_TSS, prop_kd_CHLa)

```
The table below shows the average kd value for each station, along with the percentage of kd that is associated with each variable (CDOM, TSS, CHLa). It should be noted that the effects of CHLa were insignificant as the P-value > 0.05.

```{r}
head(final_residual_df, 12)
```


## Individual Values AIC and Multiple Regression

```{r}
# Load necessary library
library(dplyr)

# Define the full dataset and predictors
response <- "kd"
predictors <- c("CDOM_ab", "TSS", "CHLa_Corrected")

# Generate all combinations of predictors
all_combinations <- unlist(
  lapply(0:length(predictors), function(x) combn(predictors, x, simplify = FALSE)), 
  recursive = FALSE
)

# Fit models for each combination and calculate AIC
model_results <- lapply(all_combinations, function(predictor_set) {
  # Create the formula for the current combination of predictors
  formula <- as.formula(paste(response, "~", ifelse(length(predictor_set) == 0, "1", paste(predictor_set, collapse = " + "))))
  
  # Fit the linear model
  model <- lm(formula, data = thes)
  
  # Return the model, predictors, and AIC
  list(
    predictors = predictor_set,
    model = model,
    AIC = AIC(model)
  )
})

# Convert results to a dataframe for easier analysis
results_df <- do.call(rbind, lapply(model_results, function(x) {
  data.frame(
    Predictors = paste(x$predictors, collapse = " + "),
    AIC = x$AIC
  )
}))

# Find the model with the lowest AIC
min_AIC <- min(results_df$AIC)

# Calculate the delta AIC for each model (difference from the minimum AIC)
results_df <- results_df %>%
  mutate(Delta_AIC = AIC - min_AIC) %>%
  arrange(Delta_AIC)  # Sort by delta AIC

# Print the results with Delta AIC
print(results_df)

```

```{r}

# Perform multiple regression
model <- lm(kd ~ CDOM_ab + TSS + CHLa_Corrected, data = thes)


# Summarize the model to view results
summary(model)

# Extract coefficients
coefs <- coef(model)

# Create the regression equation as a string with coefficients rounded to 4 decimal places
equation <- paste(
  "kd =", round(coefs[1], 4),
  "+", round(coefs[2], 4), "* CDOM_ab",
  "+", round(coefs[3], 4), "* TSS",
  "+", round(coefs[4], 4), "* CHLa_Corrected"
)

# Print the equation
equation

# Increase plot size by reducing the layout to one plot per page
par(mfrow = c(1, 1))
plot(model)


```
 
# Residuals vs Fitted Plot
The "Residuals vs Fitted" plot evaluates the assumptions of the linear regression model. Ideally, residuals (errors) should be randomly distributed around zero with no clear pattern, indicating a good fit of the model. In this plot:

1.  The residuals appear somewhat evenly distributed around the horizontal line at 0, but there is slight curvature in the red line (a loess smoother), suggesting potential non-linearity in the relationship or model misspecification.
2.  A few labeled points (e.g., 16 and 21) indicate potential influential or high-leverage observations.
3.  The variability of residuals appears relatively consistent across the range of fitted values, meaning there is no strong evidence of heteroscedasticity (changing variance).

This plot suggests the model performs reasonably but may benefit from further diagnostics or additional predictors to capture non-linear effects.

# Q-Q Plot
The Q-Q (quantile-quantile) plot evaluates whether the residuals from the regression model follow a normal distribution. In this plot:

1. The majority of points fall close to the diagonal line, indicating that the residuals generally follow a normal distribution.
2. However, deviations are observed at both ends of the plot. Points 21 and 16 at the upper end and point 5 at the lower end deviate significantly, suggesting potential outliers or non-normality in the tails.

Overall, while the residuals are approximately normal, the deviations at the extremes indicate that the model's assumptions may not hold perfectly, warranting further investigation of these specific data points.


# Scale Location Plot
The "Scale-Location" plot evaluates the assumption of homoscedasticity in a linear regression model, meaning the residuals should have constant variance across the range of fitted values. In this plot:

1. The residuals, represented as the square root of their absolute standardized values, appear somewhat randomly distributed, but the red loess smoother shows a slight upward trend at higher fitted values. This suggests potential heteroscedasticity or a mild violation of the constant variance assumption.
2. A few points, such as 16 and 21, are labeled, indicating they may be influential or outliers worth investigating further.
3. The variability of residuals is fairly consistent across most fitted values, though the upward trend in the red line warrants further inspection.
Overall, the model performs reasonably well but may benefit from adjustments, such as transforming variables or adding predictors, to address the slight non-constant variance.


# Residuals vs Leverage Plot
The Residuals vs. Leverage plot evaluates the influence of individual data points on the regression model. In this plot:

1. Most points are clustered within the lower-leverage region, indicating that the majority of observations have minimal influence on the model.
2. Points 16, 18, and 21 are positioned further from the cluster, suggesting higher leverage and potential influence on the model fit.
3. The Cook's distance lines show that none of these points exceed the threshold (Cook's distance = 1), though they may still require closer inspection due to their relatively high leverage.

Overall, while most points do not appear problematic, points with higher leverage (e.g., 16, 18, and 21) should be investigated to assess their impact on the model.


## Station Average AIC and Multiple Regression

```{r}
# Load necessary library
library(dplyr)

# Define the full dataset and predictors
response <- "mean_kd"
predictors <- c("mean_CDOM_ab", "mean_TSS", "mean_CHLa_Corrected")

# Generate all combinations of predictors
all_combinations <- unlist(
  lapply(0:length(predictors), function(x) combn(predictors, x, simplify = FALSE)), 
  recursive = FALSE
)

# Fit models for each combination and calculate AIC
model_results <- lapply(all_combinations, function(predictor_set) {
  # Create the formula for the current combination of predictors
  formula <- as.formula(paste(response, "~", ifelse(length(predictor_set) == 0, "1", paste(predictor_set, collapse = " + "))))
  
  # Fit the linear model
  model <- lm(formula, data = mean_values)
  
  # Return the model, predictors, and AIC
  list(
    predictors = predictor_set,
    model = model,
    AIC = AIC(model)
  )
})

# Convert results to a dataframe for easier analysis
results_df <- do.call(rbind, lapply(model_results, function(x) {
  data.frame(
    Predictors = paste(x$predictors, collapse = " + "),
    AIC = x$AIC
  )
}))

# Find the model with the lowest AIC
min_AIC <- min(results_df$AIC)

# Calculate the delta AIC for each model (difference from the minimum AIC)
results_df <- results_df %>%
  mutate(Delta_AIC = AIC - min_AIC) %>%
  arrange(Delta_AIC)  # Sort by delta AIC

# Print the results with Delta AIC
print(results_df)

```

```{r}

# Perform multiple regression
model <- lm(mean_kd ~ mean_CDOM_ab + mean_TSS, data = mean_values)


# Summarize the model to view results
summary(model)

# Extract coefficients
coefs <- coef(model)

# Create the regression equation as a string with coefficients rounded to 4 decimal places
equation <- paste(
  "kd =", round(coefs[1], 4),
  "+", round(coefs[2], 4), "* mean_CDOM_ab",
  "+", round(coefs[3], 4), "* mean_TSS"
)

# Print the equation
equation

# Increase plot size by reducing the layout to one plot per page
par(mfrow = c(1, 1))
plot(model)


```

# Residuals vs Fitted Plot

The "Residuals vs Fitted" plot evaluates the assumptions of the linear regression model. Ideally, residuals (errors) should be randomly distributed around zero with no clear pattern, indicating a good fit of the model. In this plot:

1. The residuals are relatively evenly distributed around the horizontal line at 0, but there is some minor curvature in the red loess smoother, hinting at potential non-linearity in the model.
2. Points labeled as 3, 11, and 12 indicate observations with potential influence that might warrant further investigation.
3. The variability of residuals is relatively consistent across the fitted values, suggesting no strong evidence of heteroscedasticity (changing variance).

This plot suggests that the model generally performs well, though minor non-linearity might indicate room for improvement or refinement in the model specification.

# Q-Q Plot

The "Q-Q Residuals" plot evaluates whether the residuals from the linear regression model follow a normal distribution. Ideally, the points should align closely with the diagonal line, indicating normally distributed residuals. In this plot:

1. Most of the points align reasonably well with the diagonal line, suggesting that the residuals are approximately normally distributed.
2. Points labeled 11, 3, and 12 deviate from the line, indicating potential outliers or observations with higher leverage that may not conform well to the normality assumption.
3. The deviations are most pronounced at the tails (extreme values), which could indicate mild departures from normality.

This plot suggests that the residuals are roughly normal, with some minor deviations that may warrant further investigation, particularly for the influential points.

# Scale-Location Plot

The "Scale-Location" plot (also called Spread-Location plot) evaluates the homoscedasticity (constant variance) assumption in a linear regression model. Ideally, the points should appear randomly scattered around the red line, with no clear pattern, and a roughly constant spread. In this plot:

1. There is some increasing trend in the red loess smoother line, especially for higher fitted values, which suggests potential heteroscedasticity (non-constant variance).
2. Observations labeled 11 and 12 show larger residuals, which may be influential points contributing to the observed trend.
3. The variability in standardized residuals is not entirely consistent, with higher variance at larger fitted values.

This plot indicates possible issues with heteroscedasticity in the model. This could mean that a transformation of the response variable or a different model might improve the fit.

# Residuals vs Leverage Plot

The Residuals vs. Leverage plot evaluates the influence of individual data points on the regression model. In this plot:

1. Most points are clustered within the lower-leverage region, indicating that the majority of observations have minimal influence on the model.
2. Points 10, 11, and 12 are positioned further from the cluster, suggesting higher leverage and potential influence on the model fit. Notably, point 11 stands out as having both higher leverage and a noticeable residual.
3. The Cook's distance lines show that none of these points exceed the threshold (Cook's distance = 1), though points 10 and 11 approach the 0.5 Cook's distance line, indicating moderate influence and requiring closer inspection.

Overall, while most points do not appear problematic, points with higher leverage (e.g., 10, 11, and 12) should be investigated to assess their impact on the model.
